{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "j3VWmAQ3BH_o"
      },
      "outputs": [],
      "source": [
        "class Gvozdomet:\n",
        "    def init(self):\n",
        "        self.img_path = None\n",
        "\n",
        "\n",
        "    def connect_model(self):\n",
        "        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path='train_num_yolov5_weights.pt', force_reload=True)\n",
        "        self.model.conf = 0.5 #–Ω–∏–∂–Ω—è—è –ø–ª–∞–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "\n",
        "\n",
        "\n",
        "    def get_number(self, pth):\n",
        "\n",
        "        # self.model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/num_weights/train_num_yolov5_weights.pt', force_reload=True)\n",
        "        # self.model.conf = 0.5 #–Ω–∏–∂–Ω—è—è –ø–ª–∞–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "\n",
        "        img = Image.open(pth)\n",
        "        img = img.resize((640, 640))\n",
        "        self.results = self.model(img)\n",
        "\n",
        "        return self.detect_train_number(pth)\n",
        "\n",
        "\n",
        "    def detect_train_number(self, pth):\n",
        "\n",
        "        reader = easyocr.Reader(['en'], gpu=False)\n",
        "\n",
        "        img = cv2.resize(cv2.imread(pth), (640, 640))\n",
        "\n",
        "        if self.results.xyxy[0].shape[0] > 0:\n",
        "            mas = self.results.xyxy[0][0].cpu().numpy().tolist()[:-2]\n",
        "            for i in range(len(mas)):\n",
        "                mas[i] = int(round(mas[i], 0))\n",
        "\n",
        "\n",
        "            img_rec = img[mas[1]:mas[3], mas[0]:mas[2]]\n",
        "\n",
        "\n",
        "            img_rec = cv2.cvtColor(img_rec, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "            detections = reader.readtext(img_rec, detail=0)\n",
        "            arr = [pth]\n",
        "            if len(detections) > 0:\n",
        "                itog_nm = \"\"\n",
        "                num = detections[0]\n",
        "                for i in num:\n",
        "                    if i in \"0123456789\":\n",
        "                        itog_nm += i\n",
        "                    elif i in \"\\|/\":\n",
        "                        itog_nm += \"1\"\n",
        "                if len(itog_nm) > 0:\n",
        "                    arr.append(1) #–¥–æ–±–∞–≤–∏–ª–∏ 1 –≤ type\n",
        "                    arr.append(int(itog_nm)) # –¥–æ–±–∞–≤–∏–ª–∏ –Ω–æ–º–µ—Ä\n",
        "\n",
        "\n",
        "                    if len(itog_nm) == 8:\n",
        "\n",
        "\n",
        "                        mnog = \"21212121\"\n",
        "                        sm = \"\"\n",
        "                        for i in range(len(itog_nm) - 1):\n",
        "                            sm += str(int(itog_nm[i]) * int(mnog[i]))\n",
        "\n",
        "                        itog_sm = 0\n",
        "                        for i in sm:\n",
        "                            itog_sm += int(i)\n",
        "\n",
        "\n",
        "                        if 10 - (itog_sm % 10) == int(itog_nm[-1]):\n",
        "                            arr.append(1) #–¥–æ–±–∞–≤–∏–ª–∏ is_correct 1 –µ—Å–ª–∏ –ø—Ä–æ—à–ª–æ\n",
        "                        else:\n",
        "                            arr.append(0)#–¥–æ–±–∞–≤–∏–ª–∏ is_correct 0 –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ—à–ª–æ\n",
        "\n",
        "                    else:\n",
        "                        arr.append(0) #–¥–æ–±–∞–≤–∏–ª–∏ is_correct 0 –µ—Å–ª–∏ –¥–ª–∏–Ω–∞ != 8\n",
        "                else:\n",
        "                    arr.append(0)\n",
        "                    arr.append(94012576)\n",
        "                    arr.append(0)\n",
        "\n",
        "\n",
        "        else: # –∑–∞–ª–∏–≤–∞–µ–º —Ñ–æ—Ä–º—É –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏\n",
        "            arr.append(0)\n",
        "            arr.append(94012576)\n",
        "            arr.append(0)\n",
        "\n",
        "        return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zNXJecpIv4N"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpp0ru6FJXFH",
        "outputId": "ed06f1c3-8b8d-406f-b600-2e53775b783d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16003, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 16003 (delta 21), reused 20 (delta 13), pack-reused 15967\u001b[K\n",
            "Receiving objects: 100% (16003/16003), 14.60 MiB | 3.96 MiB/s, done.\n",
            "Resolving deltas: 100% (10987/10987), done.\n",
            "/Users/vlyrdv/Desktop/python/hahaton_sochi/yolov5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hHpGCwrYLx_u"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRyzi0aZMDIh"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIqqv7vUL1vC",
        "outputId": "83a94b70-b0d9-425f-c2c6-a8e07b6559e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 üöÄ v7.0-226-gdd9e338 Python-3.11.4 torch-2.0.1 CPU\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete ‚úÖ (8 CPUs, 16.0 GB RAM, 233.6/460.4 GB disk)\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "import easyocr\n",
        "import torch\n",
        "import utils\n",
        "import cv2\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from PIL import Image\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "display = utils.notebook_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYrt2xgvMNZh",
        "outputId": "bcd716c4-4827-468c-fc47-36eb3564c27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/vlyrdv/Desktop/python/hahaton_sochi\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_GBEz6fMbwD",
        "outputId": "8e4a4560-f1cc-4364-eca1-ed053cb08e39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 üöÄ v7.0-226-gdd9e338 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "obj = Gvozdomet()\n",
        "\n",
        "obj.connect_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLWS4bmTNQC4",
        "outputId": "8c33665c-3792-4874-dd1f-f340b3b9a861"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/content/42343657.jpg', 1, 42343657, 1]\n"
          ]
        }
      ],
      "source": [
        "print(obj.get_number(\"/content/42343657.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIWx-J7zPTUW",
        "outputId": "d69dcf35-ce69-4cde-8f15-6b8cbb65655b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /Users/vlyrdv/.cache/torch/hub/master.zip\n",
            "YOLOv5 üöÄ v7.0-226-gdd9e338 Python-3.11.4 torch-2.0.1 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
            "Adding AutoShape... \n",
            "Using CPU. Note: This module is much faster with a GPU.\n",
            "127.0.0.1 - - [14/Oct/2023 20:40:36] \"GET /pred/42343657 HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import time\n",
        "\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ Flask-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def start():\n",
        "    return \"–ü—Ä–∏–≤–µ—Ç –¥–æ—Ä–æ–≥–æ–π –¥—Ä—É–≥\"\n",
        "\n",
        "\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ API-–º–∞—Ä—à—Ä—É—Ç–∞\n",
        "@app.route('/pred/<img_name>')\n",
        "def predict(img_name):\n",
        "    \n",
        "    obj = Gvozdomet()\n",
        "    obj.connect_model()\n",
        "    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Ç–µ–ª–∞ –∑–∞–ø—Ä–æ—Å–∞\n",
        "    image_path = f\"images/{img_name}.jpg\"\n",
        "\n",
        "    # –ü–æ–¥–∞—á–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏\n",
        "    predictions = obj.get_number(image_path)\n",
        "\n",
        "    # –í–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON\n",
        "    return {predictions[0] : {\n",
        "        \"time\": time.time(),\n",
        "        \"type\": predictions[1],\n",
        "        \"number\": predictions[2],\n",
        "        \"is_correct\": predictions[-1]\n",
        "    }}\n",
        "\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ API\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='127.0.0.1', port=5000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
